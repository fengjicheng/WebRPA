"""å·¥ä½œæµæ‰§è¡Œå™¨ - å¼‚æ­¥ç‰ˆæœ¬ï¼Œæ”¯æŒçœŸæ­£çš„å¹¶è¡Œæ‰§è¡Œ"""
import asyncio
import time
from datetime import datetime
from typing import Optional, Callable, Awaitable
from uuid import uuid4

from app.models.workflow import (
    Workflow,
    WorkflowNode,
    ExecutionResult,
    ExecutionStatus,
    LogLevel,
    LogEntry,
)
from app.executors import ExecutionContext, ModuleResult, registry
from app.services.workflow_parser import WorkflowParser, ExecutionGraph


# æ¨¡å—é»˜è®¤è¶…æ—¶æ—¶é—´é…ç½®ï¼ˆæ¯«ç§’ï¼‰
# æ ¹æ®æ¨¡å—å®é™…ä½¿ç”¨åœºæ™¯è®¾ç½®åˆç†çš„é»˜è®¤è¶…æ—¶
# è¶…æ—¶ä¸º0è¡¨ç¤ºä¸é™åˆ¶è¶…æ—¶ï¼ˆéé˜»å¡æˆ–éœ€è¦ç”¨æˆ·äº¤äº’çš„æ¨¡å—ï¼‰
MODULE_DEFAULT_TIMEOUTS = {
    # æµè§ˆå™¨æ“ä½œ - ç½‘é¡µåŠ è½½å¯èƒ½è¾ƒæ…¢
    'open_page': 60000,        # 60ç§’
    'click_element': 60000,    # 60ç§’
    'hover_element': 60000,    # 60ç§’
    'input_text': 60000,       # 60ç§’
    'get_element_info': 60000, # 60ç§’
    'wait': 0,                 # å›ºå®šç­‰å¾…ä¸éœ€è¦è¶…æ—¶ï¼ˆç”±æ¨¡å—å†…éƒ¨æ§åˆ¶ï¼‰
    'wait_element': 60000,     # 60ç§’
    'close_page': 10000,       # 10ç§’
    'refresh_page': 60000,     # 60ç§’
    'go_back': 60000,          # 60ç§’
    'go_forward': 60000,       # 60ç§’
    'handle_dialog': 60000,    # 60ç§’
    # è¡¨å•æ“ä½œ
    'select_dropdown': 60000,  # 60ç§’
    'set_checkbox': 60000,     # 60ç§’
    'drag_element': 60000,     # 60ç§’
    'scroll_page': 60000,      # 60ç§’
    'upload_file': 120000,     # 2åˆ†é’Ÿ
    # æ•°æ®å¤„ç† - é€šå¸¸å¾ˆå¿«
    'set_variable': 5000,      # 5ç§’
    'json_parse': 5000,        # 5ç§’
    'base64': 10000,           # 10ç§’
    'random_number': 5000,     # 5ç§’
    'get_time': 5000,          # 5ç§’
    'download_file': 300000,   # 5åˆ†é’Ÿ
    'save_image': 60000,       # 1åˆ†é’Ÿ
    'screenshot': 60000,       # 60ç§’
    'read_excel': 60000,       # 1åˆ†é’Ÿ
    # å­—ç¬¦ä¸²æ“ä½œ - å¾ˆå¿«
    'regex_extract': 10000,    # 10ç§’
    'string_replace': 5000,    # 5ç§’
    'string_split': 5000,      # 5ç§’
    'string_join': 5000,       # 5ç§’
    'string_concat': 5000,     # 5ç§’
    'string_trim': 5000,       # 5ç§’
    'string_case': 5000,       # 5ç§’
    'string_substring': 5000,  # 5ç§’
    # åˆ—è¡¨/å­—å…¸æ“ä½œ - å¾ˆå¿«
    'list_operation': 10000,   # 10ç§’
    'list_get': 5000,          # 5ç§’
    'list_length': 5000,       # 5ç§’
    'list_export': 60000,      # 1åˆ†é’Ÿï¼ˆå¯¼å‡ºå¯èƒ½è¾ƒæ…¢ï¼‰
    'dict_operation': 10000,   # 10ç§’
    'dict_get': 5000,          # 5ç§’
    'dict_keys': 5000,         # 5ç§’
    # æ•°æ®è¡¨æ ¼æ“ä½œ
    'table_add_row': 5000,     # 5ç§’
    'table_add_column': 5000,  # 5ç§’
    'table_set_cell': 5000,    # 5ç§’
    'table_get_cell': 5000,    # 5ç§’
    'table_delete_row': 5000,  # 5ç§’
    'table_clear': 5000,       # 5ç§’
    'table_export': 60000,     # 1åˆ†é’Ÿ
    # æ•°æ®åº“æ“ä½œ
    'db_connect': 60000,       # 60ç§’
    'db_query': 120000,        # 2åˆ†é’Ÿ
    'db_execute': 120000,      # 2åˆ†é’Ÿ
    'db_insert': 60000,        # 1åˆ†é’Ÿ
    'db_update': 60000,        # 1åˆ†é’Ÿ
    'db_delete': 60000,        # 1åˆ†é’Ÿ
    'db_close': 10000,         # 10ç§’
    # ç½‘ç»œè¯·æ±‚
    'api_request': 120000,     # 2åˆ†é’Ÿ
    'send_email': 60000,       # 1åˆ†é’Ÿ
    # AIèƒ½åŠ› - éœ€è¦è¾ƒé•¿æ—¶é—´
    'ai_chat': 180000,         # 3åˆ†é’Ÿ
    'ai_vision': 180000,       # 3åˆ†é’Ÿ
    # éªŒè¯ç 
    'ocr_captcha': 60000,      # 1åˆ†é’Ÿ
    'slider_captcha': 60000,   # 1åˆ†é’Ÿ
    # æµç¨‹æ§åˆ¶ - ä¸è¶…æ—¶ï¼ˆç”±å†…éƒ¨é€»è¾‘æ§åˆ¶ï¼‰
    'condition': 5000,         # 5ç§’
    'loop': 0,                 # å¾ªç¯æœ¬èº«ä¸è¶…æ—¶
    'foreach': 0,              # éå†æœ¬èº«ä¸è¶…æ—¶
    'break_loop': 5000,        # 5ç§’
    'continue_loop': 5000,     # 5ç§’
    'scheduled_task': 0,       # å®šæ—¶ä»»åŠ¡ä¸è¶…æ—¶
    'subflow': 0,              # å­æµç¨‹ä¸è¶…æ—¶
    # è¾…åŠ©å·¥å…·
    'print_log': 5000,         # 5ç§’
    'play_sound': 10000,       # 10ç§’
    'system_notification': 5000, # 5ç§’
    'play_music': 0,           # ä¸è¶…æ—¶ï¼ˆé˜»å¡å‹ï¼Œç­‰å¾…ç”¨æˆ·å…³é—­ï¼‰
    'play_video': 0,           # ä¸è¶…æ—¶ï¼ˆé˜»å¡å‹ï¼Œç­‰å¾…ç”¨æˆ·å…³é—­ï¼‰
    'view_image': 0,           # ä¸è¶…æ—¶ï¼ˆé˜»å¡å‹ï¼Œç­‰å¾…ç”¨æˆ·å…³é—­ï¼‰
    'input_prompt': 0,         # ä¸è¶…æ—¶ï¼ˆé˜»å¡å‹ï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥ï¼‰
    'text_to_speech': 120000,  # 2åˆ†é’Ÿ
    'js_script': 60000,        # 1åˆ†é’Ÿ
    'set_clipboard': 5000,     # 5ç§’
    'get_clipboard': 5000,     # 5ç§’
    'keyboard_action': 10000,  # 10ç§’
    'real_mouse_scroll': 10000,# 10ç§’
    # ç³»ç»Ÿæ“ä½œ
    'shutdown_system': 60000,  # 60ç§’
    'lock_screen': 10000,      # 10ç§’
    'window_focus': 10000,     # 10ç§’
    'real_mouse_click': 10000, # 10ç§’
    'real_mouse_move': 10000,  # 10ç§’
    'real_mouse_drag': 10000,  # 10ç§’
    'real_keyboard': 60000,    # 60ç§’
    'run_command': 300000,     # 5åˆ†é’Ÿ
    'click_image': 60000,      # 1åˆ†é’Ÿ
    'click_text': 120000,      # 2åˆ†é’Ÿï¼ˆOCRè¯†åˆ«è¾ƒæ…¢ï¼Œé¦–æ¬¡éœ€è¦ä¸‹è½½æ¨¡å‹ï¼‰
    'hover_image': 60000,      # 1åˆ†é’Ÿ
    'hover_text': 120000,      # 2åˆ†é’Ÿï¼ˆOCRè¯†åˆ«è¾ƒæ…¢ï¼‰
    'drag_image': 60000,       # 1åˆ†é’Ÿ
    'get_mouse_position': 5000,# 5ç§’
    'screenshot_screen': 10000,# 10ç§’
    'rename_file': 10000,      # 10ç§’
    'network_capture': 0,      # ä¸è¶…æ—¶ï¼ˆéé˜»å¡ï¼Œåå°è¿è¡Œï¼‰
    'macro_recorder': 0,       # ä¸è¶…æ—¶ï¼ˆå®æ’­æ”¾æ—¶é—´ç”±ç”¨æˆ·å½•åˆ¶å†…å®¹å†³å®šï¼‰
    # ç½‘ç»œå…±äº« - éé˜»å¡ï¼ˆå¯åŠ¨æœåŠ¡åç«‹å³è¿”å›ï¼‰
    'share_folder': 10000,     # 10ç§’ï¼ˆå¯åŠ¨æœåŠ¡ï¼‰
    'share_file': 10000,       # 10ç§’ï¼ˆå¯åŠ¨æœåŠ¡ï¼‰
    'stop_share': 5000,        # 5ç§’
    # å±å¹•å…±äº« - éé˜»å¡ï¼ˆå¯åŠ¨æœåŠ¡åç«‹å³è¿”å›ï¼‰
    'start_screen_share': 10000,  # 10ç§’ï¼ˆå¯åŠ¨æœåŠ¡ï¼‰
    'stop_screen_share': 5000,    # 5ç§’
    # æ–‡ä»¶æ“ä½œ
    'list_files': 60000,       # 60ç§’
    'copy_file': 300000,       # 5åˆ†é’Ÿ
    'move_file': 300000,       # 5åˆ†é’Ÿ
    'delete_file': 60000,      # 60ç§’
    'create_folder': 10000,    # 10ç§’
    'file_exists': 5000,       # 5ç§’
    'get_file_info': 10000,    # 10ç§’
    'read_text_file': 60000,   # 1åˆ†é’Ÿ
    'write_text_file': 60000,  # 1åˆ†é’Ÿ
    'rename_folder': 10000,    # 10ç§’
    # åª’ä½“å¤„ç† - FFmpegæ“ä½œè€—æ—¶
    'format_convert': 600000,  # 10åˆ†é’Ÿ
    'compress_image': 120000,  # 2åˆ†é’Ÿ
    'compress_video': 1800000, # 30åˆ†é’Ÿ
    'extract_audio': 300000,   # 5åˆ†é’Ÿ
    'trim_video': 600000,      # 10åˆ†é’Ÿ
    'merge_media': 1800000,    # 30åˆ†é’Ÿ
    'add_watermark': 600000,   # 10åˆ†é’Ÿ
    'download_m3u8': 1800000,  # 30åˆ†é’Ÿï¼ˆä¸‹è½½å¯èƒ½å¾ˆæ…¢ï¼‰
    'rotate_video': 600000,    # 10åˆ†é’Ÿ
    'video_speed': 600000,     # 10åˆ†é’Ÿ
    'extract_frame': 60000,    # 1åˆ†é’Ÿ
    'add_subtitle': 600000,    # 10åˆ†é’Ÿ
    'adjust_volume': 300000,   # 5åˆ†é’Ÿ
    'resize_video': 600000,    # 10åˆ†é’Ÿ
    # å›¾åƒå¤„ç†
    'image_grayscale': 60000,  # 1åˆ†é’Ÿ
    'image_round_corners': 60000, # 1åˆ†é’Ÿ
    # éŸ³é¢‘å¤„ç†
    'audio_to_text': 300000,   # 5åˆ†é’Ÿï¼ˆè¯­éŸ³è¯†åˆ«å¯èƒ½è¾ƒæ…¢ï¼‰
    # äºŒç»´ç 
    'qr_generate': 10000,      # 10ç§’
    'qr_decode': 60000,        # 60ç§’
    # å½•å± - éé˜»å¡ï¼ˆå¯åŠ¨åç«‹å³è¿”å›ï¼Œåå°å½•åˆ¶ï¼‰
    'screen_record': 10000,    # 10ç§’ï¼ˆå¯åŠ¨å½•å±ï¼‰
    # AIè¯†åˆ«
    'face_recognition': 60000, # 1åˆ†é’Ÿ
    'image_ocr': 60000,        # 1åˆ†é’Ÿ
    # PDFå¤„ç†
    'pdf_to_images': 300000,   # 5åˆ†é’Ÿ
    'images_to_pdf': 300000,   # 5åˆ†é’Ÿ
    'pdf_merge': 300000,       # 5åˆ†é’Ÿ
    'pdf_split': 300000,       # 5åˆ†é’Ÿ
    'pdf_extract_text': 120000,# 2åˆ†é’Ÿ
    'pdf_extract_images': 300000, # 5åˆ†é’Ÿ
    'pdf_encrypt': 60000,      # 1åˆ†é’Ÿ
    'pdf_decrypt': 60000,      # 1åˆ†é’Ÿ
    'pdf_add_watermark': 300000, # 5åˆ†é’Ÿ
    'pdf_rotate': 120000,      # 2åˆ†é’Ÿ
    'pdf_delete_pages': 120000,# 2åˆ†é’Ÿ
    'pdf_get_info': 60000,     # 60ç§’
    'pdf_compress': 600000,    # 10åˆ†é’Ÿ
    'pdf_insert_pages': 300000,# 5åˆ†é’Ÿ
    'pdf_reorder_pages': 120000, # 2åˆ†é’Ÿ
    'pdf_to_word': 600000,     # 10åˆ†é’Ÿ
    # å…¶ä»–
    'export_log': 60000,       # 60ç§’
    # è§¦å‘å™¨æ¨¡å— - ä¸è¶…æ—¶ï¼ˆç­‰å¾…äº‹ä»¶è§¦å‘ï¼‰
    'webhook_trigger': 0,      # ä¸è¶…æ—¶ï¼ˆç­‰å¾…webhookè¯·æ±‚ï¼‰
    'hotkey_trigger': 0,       # ä¸è¶…æ—¶ï¼ˆç­‰å¾…çƒ­é”®è§¦å‘ï¼‰
    'file_watcher_trigger': 0, # ä¸è¶…æ—¶ï¼ˆç­‰å¾…æ–‡ä»¶å˜åŒ–ï¼‰
    'email_trigger': 0,        # ä¸è¶…æ—¶ï¼ˆç­‰å¾…é‚®ä»¶ï¼‰
    'api_trigger': 0,          # ä¸è¶…æ—¶ï¼ˆç­‰å¾…APIè¯·æ±‚ï¼‰
    'mouse_trigger': 0,        # ä¸è¶…æ—¶ï¼ˆç­‰å¾…é¼ æ ‡äº‹ä»¶ï¼‰
    'image_trigger': 0,        # ä¸è¶…æ—¶ï¼ˆç­‰å¾…å›¾åƒå‡ºç°ï¼‰
    'sound_trigger': 0,        # ä¸è¶…æ—¶ï¼ˆç­‰å¾…å£°éŸ³ï¼‰
    'face_trigger': 0,         # ä¸è¶…æ—¶ï¼ˆç­‰å¾…äººè„¸ï¼‰
    'element_change_trigger': 0, # ä¸è¶…æ—¶ï¼ˆç­‰å¾…å…ƒç´ å˜åŒ–ï¼‰
    # QQè‡ªåŠ¨åŒ–
    'qq_wait_message': 0,      # ä¸è¶…æ—¶ï¼ˆé˜»å¡å‹ï¼Œç­‰å¾…æ¶ˆæ¯ï¼‰
    'qq_send_message': 60000,  # 60ç§’
    'qq_send_image': 60000,    # 1åˆ†é’Ÿ
    'qq_send_file': 120000,    # 2åˆ†é’Ÿ
    'qq_get_friends': 60000,   # 60ç§’
    'qq_get_groups': 60000,    # 60ç§’
    'qq_get_group_members': 60000, # 60ç§’
    'qq_get_login_info': 10000,# 10ç§’
    # å¾®ä¿¡è‡ªåŠ¨åŒ–
    'wechat_wait_message': 0,  # ä¸è¶…æ—¶ï¼ˆé˜»å¡å‹ï¼Œç­‰å¾…æ¶ˆæ¯ï¼‰
    'wechat_send_message': 60000,  # 60ç§’
    'wechat_send_file': 120000,    # 2åˆ†é’Ÿ
    'wechat_get_messages': 60000,  # 60ç§’
    'wechat_get_sessions': 60000,  # 60ç§’
    'wechat_get_login_info': 10000,# 10ç§’
    # åˆ†ç»„/å¤‡æ³¨ - ä¸æ‰§è¡Œ
    'group': 0,
    'note': 0,
}


def get_module_default_timeout(module_type: str) -> int:
    """è·å–æ¨¡å—é»˜è®¤è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰"""
    return MODULE_DEFAULT_TIMEOUTS.get(module_type, 60000)  # é»˜è®¤60ç§’ï¼Œé¿å…30ç§’è¶…æ—¶è¿‡çŸ­


class WorkflowExecutor:
    """å·¥ä½œæµæ‰§è¡Œå™¨ - ä½¿ç”¨å¼‚æ­¥Playwrightå®ç°çœŸæ­£çš„å¹¶è¡Œæ‰§è¡Œ"""
    
    def __init__(
        self,
        workflow: Workflow,
        on_log: Optional[Callable[[LogEntry], Awaitable[None]]] = None,
        on_node_start: Optional[Callable[[str], Awaitable[None]]] = None,
        on_node_complete: Optional[Callable[[str, ModuleResult], Awaitable[None]]] = None,
        on_variable_update: Optional[Callable[[str, any], Awaitable[None]]] = None,
        on_data_row: Optional[Callable[[dict], Awaitable[None]]] = None,
        headless: bool = False,
        browser_config: Optional[dict] = None,
    ):
        self.workflow = workflow
        self.on_log = on_log
        self.on_node_start = on_node_start
        self.on_node_complete = on_node_complete
        self.on_variable_update = on_variable_update
        self.on_data_row = on_data_row
        self.headless = headless
        self.browser_config = browser_config
        
        self.context = ExecutionContext(headless=headless, browser_config=browser_config)
        self._setup_progress_callback()
        self.graph: Optional[ExecutionGraph] = None
        self.is_running = False
        self.should_stop = False
        
        self.executed_nodes = 0
        self.failed_nodes = 0
        self.start_time: Optional[datetime] = None
        
        self._result: Optional[ExecutionResult] = None
        
        # å¹¶è¡Œæ‰§è¡Œç›¸å…³
        self._executed_node_ids: set[str] = set()
        self._executing_node_ids: set[str] = set()
        self._node_lock = asyncio.Lock()
        self._pending_nodes: dict[str, set[str]] = {}
        self._last_data_rows_count = 0
        self._sent_data_rows_count = 0
        self._running_tasks: set[asyncio.Task] = set()  # è·Ÿè¸ªæ‰€æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡

    def _setup_progress_callback(self):
        """è®¾ç½®è¿›åº¦å›è°ƒï¼Œè®©æ¨¡å—æ‰§è¡Œå™¨å¯ä»¥å‘é€è¿›åº¦æ—¥å¿—"""
        async def progress_callback(message: str, level: str = "info"):
            level_map = {
                'info': LogLevel.INFO,
                'warning': LogLevel.WARNING,
                'error': LogLevel.ERROR,
                'success': LogLevel.SUCCESS
            }
            log_level = level_map.get(level, LogLevel.INFO)
            await self._log(log_level, message, is_system_log=True)
        
        self.context._progress_callback = progress_callback
        
        # è®¾ç½®å˜é‡æ›´æ–°å›è°ƒ
        async def variable_update_callback(name: str, value: any):
            await self._notify_variable_update(name, value)
        
        self.context._variable_update_callback = variable_update_callback

    async def _log(self, level: LogLevel, message: str, node_id: Optional[str] = None, 
                   details: Optional[dict] = None, duration: Optional[float] = None,
                   is_user_log: bool = False, is_system_log: bool = False):
        """è®°å½•æ—¥å¿—"""
        log_details = details.copy() if details else {}
        log_details['is_user_log'] = is_user_log
        log_details['is_system_log'] = is_system_log
        
        entry = LogEntry(
            id=str(uuid4()),
            timestamp=datetime.now(),
            level=level,
            node_id=node_id,
            message=message,
            details=log_details,
            duration=duration,
        )
        
        # åŒæ—¶å­˜å‚¨åˆ° context._logs ä¸­ï¼ˆç”¨äºå¯¼å‡ºæ—¥å¿—æ¨¡å—ï¼‰
        level_str = level.value if hasattr(level, 'value') else str(level)
        timestamp_str = entry.timestamp.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
        self.context.add_log(
            level=level_str,
            message=message,
            node_id=node_id,
            duration=duration,
            timestamp=timestamp_str
        )
        
        if self.on_log:
            try:
                await self.on_log(entry)
            except Exception as e:
                print(f"å‘é€æ—¥å¿—å¤±è´¥: {e}")
    
    async def _send_data_row(self, row_data: dict):
        """å‘é€æ•°æ®è¡Œåˆ°å‰ç«¯"""
        MAX_PREVIEW_ROWS = 20
        if self._sent_data_rows_count >= MAX_PREVIEW_ROWS:
            return
        if self.on_data_row:
            try:
                await self.on_data_row(row_data)
            except Exception as e:
                print(f"å‘é€æ•°æ®è¡Œå¤±è´¥: {e}")
        self._sent_data_rows_count += 1
    
    async def _notify_node_start(self, node_id: str):
        """é€šçŸ¥èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ"""
        if self.on_node_start:
            try:
                await self.on_node_start(node_id)
            except Exception as e:
                print(f"é€šçŸ¥èŠ‚ç‚¹å¼€å§‹å¤±è´¥: {e}")
    
    async def _notify_node_complete(self, node_id: str, result: ModuleResult):
        """é€šçŸ¥èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ"""
        if self.on_node_complete:
            try:
                await self.on_node_complete(node_id, result)
            except Exception as e:
                print(f"é€šçŸ¥èŠ‚ç‚¹å®Œæˆå¤±è´¥: {e}")
    
    async def _notify_variable_update(self, name: str, value: any):
        """é€šçŸ¥å˜é‡æ›´æ–°"""
        if self.on_variable_update:
            try:
                await self.on_variable_update(name, value)
            except Exception as e:
                print(f"é€šçŸ¥å˜é‡æ›´æ–°å¤±è´¥: {e}")

    async def _execute_parallel(self, node_ids: list[str]):
        """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªèŠ‚ç‚¹åˆ†æ”¯"""
        if not node_ids or self.should_stop:
            return
        
        # è¿‡æ»¤æ‰å­æµç¨‹èŠ‚ç‚¹ï¼ˆå¦‚æœå·²ç»æ”¶é›†äº†å­æµç¨‹èŠ‚ç‚¹åˆ—è¡¨ï¼‰
        if hasattr(self, '_subflow_node_ids'):
            filtered_node_ids = [nid for nid in node_ids if nid not in self._subflow_node_ids]
            if len(filtered_node_ids) < len(node_ids):
                skipped = len(node_ids) - len(filtered_node_ids)
                print(f"[DEBUG] è¿‡æ»¤æ‰ {skipped} ä¸ªå­æµç¨‹èŠ‚ç‚¹")
            node_ids = filtered_node_ids
        
        if not node_ids:
            return
        
        async with self._node_lock:
            nodes_to_execute = [
                nid for nid in node_ids 
                if nid not in self._executed_node_ids and nid not in self._executing_node_ids
            ]
            if not nodes_to_execute:
                return
            for nid in nodes_to_execute:
                self._executing_node_ids.add(nid)
        
        # è°ƒè¯•ï¼šæ‰“å°è¦æ‰§è¡Œçš„èŠ‚ç‚¹
        for nid in nodes_to_execute:
            node = self.graph.get_node(nid)
            if node:
                label = node.data.get('label', node.type)
                print(f"[DEBUG] å‡†å¤‡æ‰§è¡ŒèŠ‚ç‚¹: {nid} ({node.type}: {label})")
        
        if len(nodes_to_execute) == 1:
            if self.should_stop:
                return
            task = asyncio.create_task(self._execute_from_node(nodes_to_execute[0]))
            self._running_tasks.add(task)
            try:
                await task
            except asyncio.CancelledError:
                pass
            finally:
                self._running_tasks.discard(task)
        else:
            await self._log(LogLevel.INFO, f"ğŸ”€ æ£€æµ‹åˆ° {len(nodes_to_execute)} ä¸ªåˆ†æ”¯ï¼Œå¹¶è¡Œæ‰§è¡Œ...")
            tasks = []
            for node_id in nodes_to_execute:
                if self.should_stop:
                    break
                task = asyncio.create_task(self._execute_from_node(node_id))
                self._running_tasks.add(task)
                tasks.append(task)
            
            if tasks:
                try:
                    await asyncio.gather(*tasks, return_exceptions=True)
                except asyncio.CancelledError:
                    pass
                finally:
                    for task in tasks:
                        self._running_tasks.discard(task)
            
            if not self.should_stop:
                await self._log(LogLevel.INFO, f"ğŸ”€ {len(nodes_to_execute)} ä¸ªåˆ†æ”¯æ‰§è¡Œå®Œæˆ")
    
    async def _execute_from_node(self, node_id: str):
        """ä»æŒ‡å®šèŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ"""
        if self.should_stop:
            return
        
        async with self._node_lock:
            if node_id in self._executed_node_ids:
                return
            self._executing_node_ids.add(node_id)
        
        node = self.graph.get_node(node_id)
        if not node:
            async with self._node_lock:
                self._executing_node_ids.discard(node_id)
            return
        
        result = await self._execute_node(node)
        
        async with self._node_lock:
            self._executed_node_ids.add(node_id)
            self._executing_node_ids.discard(node_id)
        
        if self.should_stop:
            return
        
        if self.context.should_break:
            return
        
        if self.context.should_continue:
            return
        
        if result and result.branch:
            next_nodes = self.graph.get_next_nodes(node_id, result.branch)
        else:
            next_nodes = self.graph.get_next_nodes(node_id)
        
        # å¦‚æœèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å¤„ç†åˆ†æ”¯
        if result and not result.success:
            error_nodes = self.graph.get_error_nodes(node_id)
            if error_nodes:
                # æœ‰å¼‚å¸¸å¤„ç†åˆ†æ”¯ï¼Œæ‰§è¡Œå¼‚å¸¸å¤„ç†æµç¨‹
                print(f"[DEBUG] èŠ‚ç‚¹ {node.type} å¤±è´¥ï¼Œè§¦å‘å¼‚å¸¸å¤„ç†åˆ†æ”¯")
                await self._log(LogLevel.WARNING, f"âš ï¸ èŠ‚ç‚¹å¤±è´¥ï¼Œè§¦å‘å¼‚å¸¸å¤„ç†æµç¨‹", node_id=node_id)
                await self._execute_parallel(error_nodes)
                return
            else:
                # æ²¡æœ‰å¼‚å¸¸å¤„ç†åˆ†æ”¯ï¼Œå¯¹äºå…³é”®èŠ‚ç‚¹åœæ­¢æ‰§è¡Œ
                if node.type in ('open_page', 'click_element', 'input_text', 'wait_element', 'select_dropdown'):
                    print(f"[DEBUG] å…³é”®èŠ‚ç‚¹ {node.type} å¤±è´¥ï¼Œåœæ­¢åç»­æ‰§è¡Œ")
                    return
        
        if node.type in ('loop', 'foreach'):
            body_nodes = self.graph.get_loop_body_nodes(node_id)
            done_nodes = self.graph.get_loop_done_nodes(node_id)
            await self._handle_loop(node, body_nodes, done_nodes)
        else:
            await self._notify_successors(next_nodes, node_id)


    async def _notify_successors(self, next_nodes: list[str], completed_node_id: str):
        """é€šçŸ¥åç»§èŠ‚ç‚¹å½“å‰èŠ‚ç‚¹å·²å®Œæˆ"""
        if not next_nodes or self.should_stop:
            return
        
        nodes_ready_to_execute = []
        
        async with self._node_lock:
            for next_id in next_nodes:
                if next_id in self._executed_node_ids or next_id in self._executing_node_ids:
                    continue
                
                prev_nodes = self.graph.get_prev_nodes(next_id)
                
                if len(prev_nodes) <= 1:
                    nodes_ready_to_execute.append(next_id)
                    continue
                
                if next_id not in self._pending_nodes:
                    self._pending_nodes[next_id] = set(
                        pid for pid in prev_nodes if pid not in self._executed_node_ids
                    )
                
                self._pending_nodes[next_id].discard(completed_node_id)
                
                if len(self._pending_nodes[next_id]) == 0:
                    nodes_ready_to_execute.append(next_id)
                    del self._pending_nodes[next_id]
                else:
                    remaining = len(self._pending_nodes[next_id])
                    await self._log(LogLevel.INFO, f"â³ ç­‰å¾…æ±‡åˆ: è¿˜æœ‰ {remaining} ä¸ªå‰é©±åˆ†æ”¯æœªå®Œæˆ")
        
        if nodes_ready_to_execute:
            await self._execute_parallel(nodes_ready_to_execute)

    async def _execute_node(self, node: WorkflowNode) -> Optional[ModuleResult]:
        """æ‰§è¡Œå•ä¸ªèŠ‚ç‚¹"""
        if self.should_stop:
            return None
        
        # è·³è¿‡åˆ†ç»„ã€ä¾¿ç­¾å’Œå­æµç¨‹å¤´èŠ‚ç‚¹
        if node.type in ('group', 'note', 'subflow_header'):
            return ModuleResult(success=True, message="è·³è¿‡")
        
        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦è¢«ç¦ç”¨
        if node.data.get('disabled', False):
            label = node.data.get('label', node.type)
            return ModuleResult(success=True, message=f"å·²è·³è¿‡ï¼ˆç¦ç”¨ï¼‰")
        
        label = node.data.get('label', node.type)
        print(f"[DEBUG] å¼€å§‹æ‰§è¡ŒèŠ‚ç‚¹: {node.id} ({node.type}: {label})")
        
        await self._notify_node_start(node.id)
        
        executor = registry.get(node.type)
        if not executor:
            print(f"[DEBUG] æœªæ‰¾åˆ°æ‰§è¡Œå™¨: {node.type}")
            await self._log(LogLevel.WARNING, f"æœªçŸ¥çš„æ¨¡å—ç±»å‹: {node.type}", node_id=node.id)
            return ModuleResult(success=True, message=f"è·³è¿‡æœªçŸ¥æ¨¡å—: {node.type}")
        
        config = node.data.get('config', None)
        if config is None:
            # é…ç½®ç›´æ¥åœ¨ node.data ä¸­ï¼Œè€Œä¸æ˜¯åœ¨ config å­å­—æ®µ
            config = node.data
        print(f"[DEBUG] èŠ‚ç‚¹é…ç½®: {config}")
        
        # è·å–è¶…æ—¶é…ç½®ï¼ˆæ¯«ç§’ï¼‰
        # å¯¹äºæŸäº›æ¨¡å—ï¼ˆå¦‚ qq_wait_messageï¼‰ï¼Œå¼ºåˆ¶ä½¿ç”¨æ¨¡å—é»˜è®¤è¶…æ—¶ï¼Œå¿½ç•¥èŠ‚ç‚¹é…ç½®ä¸­çš„ timeout å­—æ®µ
        # å› ä¸ºè¿™äº›æ¨¡å—æœ‰è‡ªå·±å†…éƒ¨çš„è¶…æ—¶é€»è¾‘ï¼ˆå¦‚ waitTimeoutï¼‰
        modules_with_internal_timeout = {'qq_wait_message', 'wechat_wait_message', 'wait', 'loop', 'foreach', 'scheduled_task', 'subflow', 
                                          'play_music', 'play_video', 'view_image', 'input_prompt'}
        
        if node.type in modules_with_internal_timeout:
            # è¿™äº›æ¨¡å—å¼ºåˆ¶ä½¿ç”¨æ¨¡å—é»˜è®¤è¶…æ—¶ï¼ˆé€šå¸¸æ˜¯0ï¼Œè¡¨ç¤ºæ— è¶…æ—¶é™åˆ¶ï¼‰
            timeout_ms = get_module_default_timeout(node.type)
        else:
            # ä¼˜å…ˆä½¿ç”¨èŠ‚ç‚¹é…ç½®çš„è¶…æ—¶ï¼Œå¦åˆ™ä½¿ç”¨æ¨¡å—é»˜è®¤è¶…æ—¶
            timeout_ms = config.get('timeout')
            if timeout_ms is None:
                timeout_ms = get_module_default_timeout(node.type)
            try:
                timeout_ms = int(timeout_ms)
            except (ValueError, TypeError):
                timeout_ms = get_module_default_timeout(node.type)
        
        # è¶…æ—¶ä¸º0è¡¨ç¤ºä¸é™åˆ¶è¶…æ—¶
        if timeout_ms <= 0:
            timeout_seconds = None  # æ— è¶…æ—¶é™åˆ¶
        else:
            timeout_seconds = timeout_ms / 1000.0
        
        start_time = time.time()
        
        try:
            timeout_display = f"{timeout_seconds}ç§’" if timeout_seconds else "æ— é™åˆ¶"
            print(f"[DEBUG] è°ƒç”¨æ‰§è¡Œå™¨: {node.type}, è¶…æ—¶: {timeout_display}")
            
            # ä½¿ç”¨ asyncio.wait_for æ¥æ§åˆ¶è¶…æ—¶ï¼ˆå¦‚æœæœ‰è¶…æ—¶é™åˆ¶ï¼‰
            try:
                if timeout_seconds is not None:
                    result = await asyncio.wait_for(
                        executor.execute(config, self.context),
                        timeout=timeout_seconds
                    )
                else:
                    # æ— è¶…æ—¶é™åˆ¶ï¼Œç›´æ¥æ‰§è¡Œ
                    result = await executor.execute(config, self.context)
            except asyncio.TimeoutError:
                duration = (time.time() - start_time) * 1000
                error_msg = f"æ‰§è¡Œè¶…æ—¶ ({timeout_ms}ms)"
                print(f"[ERROR] èŠ‚ç‚¹ {node.id} ({label}) {error_msg}")
                return ModuleResult(success=False, error=error_msg, duration=duration)
            
            print(f"[DEBUG] æ‰§è¡Œå™¨è¿”å›: success={result.success}, message={result.message}, error={result.error}")
            
            # å¤„ç†å­æµç¨‹è°ƒç”¨
            if node.type == 'subflow' and result.success and result.data:
                subflow_group_id = result.data.get('subflow_group_id')
                subflow_name = config.get('subflowName', '')
                if subflow_group_id:
                    subflow_result = await self._execute_subflow_group(subflow_group_id, subflow_name)
                    if not subflow_result.success:
                        result = subflow_result
            
            duration = (time.time() - start_time) * 1000
            result.duration = duration
            
            self.executed_nodes += 1
            
            if result.success:
                # é‡è¦æ¨¡å—åˆ—è¡¨ - è¿™äº›æ¨¡å—çš„æ—¥å¿—åœ¨ç®€æ´æ¨¡å¼ä¸‹ä¹Ÿä¼šæ˜¾ç¤º
                # åŒ…æ‹¬ï¼šç”¨æˆ·äº¤äº’ã€ç½‘ç»œè¯·æ±‚ã€æ–‡ä»¶å…±äº«ã€AIã€æ•°æ®åº“ã€é‚®ä»¶ã€å‘½ä»¤æ‰§è¡Œç­‰
                important_modules = {
                    # ç”¨æˆ·äº¤äº’/è¾“å‡º
                    'print_log',           # ç”¨æˆ·æ‰“å°æ—¥å¿—
                    'input_prompt',        # è¾“å…¥æç¤º - æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
                    'system_notification', # ç³»ç»Ÿé€šçŸ¥
                    'text_to_speech',      # æ–‡å­—è½¬è¯­éŸ³
                    
                    # ç½‘ç»œå…±äº«
                    'share_folder',        # æ–‡ä»¶å¤¹å…±äº« - æ˜¾ç¤ºè®¿é—®åœ°å€
                    'share_file',          # æ–‡ä»¶å…±äº« - æ˜¾ç¤ºè®¿é—®åœ°å€
                    'stop_share',          # åœæ­¢å…±äº«
                    
                    # å±å¹•å…±äº«
                    'start_screen_share',  # å¼€å§‹å±å¹•å…±äº« - æ˜¾ç¤ºè®¿é—®åœ°å€
                    'stop_screen_share',   # åœæ­¢å±å¹•å…±äº«
                    
                    # ç½‘ç»œè¯·æ±‚
                    'api_request',         # APIè¯·æ±‚ - æ˜¾ç¤ºè¯·æ±‚ç»“æœ
                    'send_email',          # å‘é€é‚®ä»¶ - æ˜¾ç¤ºå‘é€ç»“æœ
                    
                    # æ•°æ®åº“æ“ä½œ
                    'db_connect',          # æ•°æ®åº“è¿æ¥ - æ˜¾ç¤ºè¿æ¥çŠ¶æ€
                    'db_query',            # æ•°æ®åº“æŸ¥è¯¢ - æ˜¾ç¤ºæŸ¥è¯¢ç»“æœ
                    'db_execute',          # æ•°æ®åº“æ‰§è¡Œ - æ˜¾ç¤ºæ‰§è¡Œç»“æœ
                    'db_insert',           # æ•°æ®åº“æ’å…¥
                    'db_update',           # æ•°æ®åº“æ›´æ–°
                    'db_delete',           # æ•°æ®åº“åˆ é™¤
                    'db_close',            # æ•°æ®åº“å…³é—­
                    
                    # AIèƒ½åŠ›
                    'ai_chat',             # AIå¯¹è¯ - æ˜¾ç¤ºAIå›å¤
                    'ai_vision',           # AIè§†è§‰ - æ˜¾ç¤ºè¯†åˆ«ç»“æœ
                    
                    # å›¾åƒ/æ–‡æœ¬è¯†åˆ«ç‚¹å‡»
                    'click_image',         # ç‚¹å‡»å›¾åƒ - æ˜¾ç¤ºç‚¹å‡»ç»“æœ
                    'click_text',          # ç‚¹å‡»æ–‡æœ¬ - æ˜¾ç¤ºç‚¹å‡»ç»“æœ
                    'hover_image',         # æ‚¬åœå›¾åƒ
                    'hover_text',          # æ‚¬åœæ–‡æœ¬
                    'image_ocr',           # OCRè¯†åˆ« - æ˜¾ç¤ºè¯†åˆ«ç»“æœ
                    
                    # å‘½ä»¤/è„šæœ¬æ‰§è¡Œ
                    'run_command',         # è¿è¡Œå‘½ä»¤ - æ˜¾ç¤ºæ‰§è¡Œç»“æœ
                    'js_script',           # è¿è¡ŒJSè„šæœ¬
                    
                    # æ–‡ä»¶æ“ä½œ
                    'download_file',       # ä¸‹è½½æ–‡ä»¶ - æ˜¾ç¤ºä¸‹è½½ç»“æœ
                    'upload_file',         # ä¸Šä¼ æ–‡ä»¶ - æ˜¾ç¤ºä¸Šä¼ ç»“æœ
                    'read_text_file',      # è¯»å–æ–‡ä»¶ - æ˜¾ç¤ºè¯»å–ç»“æœ
                    'write_text_file',     # å†™å…¥æ–‡ä»¶ - æ˜¾ç¤ºå†™å…¥ç»“æœ
                    'copy_file',           # å¤åˆ¶æ–‡ä»¶
                    'move_file',           # ç§»åŠ¨æ–‡ä»¶
                    'delete_file',         # åˆ é™¤æ–‡ä»¶
                    'rename_file',         # é‡å‘½åæ–‡ä»¶
                    
                    # QQè‡ªåŠ¨åŒ–
                    'qq_send_message',     # QQå‘é€æ¶ˆæ¯
                    'qq_send_image',       # QQå‘é€å›¾ç‰‡
                    'qq_send_file',        # QQå‘é€æ–‡ä»¶
                    'qq_wait_message',     # QQç­‰å¾…æ¶ˆæ¯
                    
                    # å¾®ä¿¡è‡ªåŠ¨åŒ–
                    'wechat_send_message', # å¾®ä¿¡å‘é€æ¶ˆæ¯
                    'wechat_send_file',    # å¾®ä¿¡å‘é€æ–‡ä»¶
                    
                    # å­æµç¨‹
                    'subflow',             # å­æµç¨‹è°ƒç”¨
                    
                    # å½•å±
                    'screen_record',       # å½•å±
                    
                    # éŸ³é¢‘å¤„ç†
                    'audio_to_text',       # éŸ³é¢‘è½¬æ–‡å­—
                    
                    # å¯¼å‡º
                    'export_log',          # å¯¼å‡ºæ—¥å¿—
                    'table_export',        # å¯¼å‡ºè¡¨æ ¼
                    'list_export',         # å¯¼å‡ºåˆ—è¡¨
                }
                is_user_log = node.type in important_modules
                
                # è§¦å‘å™¨æ¨¡å—æ ‡è®°ä¸ºç³»ç»Ÿæ—¥å¿—
                trigger_modules = {
                    'webhook_trigger',
                    'hotkey_trigger',
                    'file_watcher_trigger',
                    'email_trigger',
                    'api_trigger',
                    'mouse_trigger',
                    'image_trigger',
                    'sound_trigger',
                    'face_trigger',
                    'element_change_trigger',
                }
                is_system_log = node.type in trigger_modules
                
                log_level = LogLevel.INFO
                if node.type == 'print_log' and result.log_level:
                    level_map = {'info': LogLevel.INFO, 'warning': LogLevel.WARNING, 
                                 'error': LogLevel.ERROR, 'success': LogLevel.SUCCESS}
                    log_level = level_map.get(result.log_level, LogLevel.INFO)
                
                await self._log(log_level, f"[{label}] {result.message}", 
                               node_id=node.id, duration=duration, is_user_log=is_user_log, is_system_log=is_system_log)
            else:
                self.failed_nodes += 1
                print(f"[ERROR] èŠ‚ç‚¹å¤±è´¥: {label} - {result.error}")
                await self._log(LogLevel.ERROR, f"[{label}] {result.error}", 
                               node_id=node.id, duration=duration)
            
            current_rows_count = len(self.context.data_rows)
            if current_rows_count > self._last_data_rows_count:
                for i in range(self._last_data_rows_count, current_rows_count):
                    await self._send_data_row(self.context.data_rows[i])
                self._last_data_rows_count = current_rows_count
            
            await self._notify_node_complete(node.id, result)
            return result
            
        except Exception as e:
            import traceback
            duration = (time.time() - start_time) * 1000
            self.failed_nodes += 1
            error_msg = f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"
            print(f"[ERROR] èŠ‚ç‚¹ {node.id} ({label}) æ‰§è¡Œå¤±è´¥: {e}")
            traceback.print_exc()
            await self._log(LogLevel.ERROR, f"[{label}] {error_msg}", node_id=node.id, duration=duration)
            result = ModuleResult(success=False, error=error_msg, duration=duration)
            await self._notify_node_complete(node.id, result)
            return result

    def _parse_dimension(self, value, default: int = 300) -> int:
        """è§£æå°ºå¯¸å€¼ï¼Œæ”¯æŒæ•°å­—å’Œå­—ç¬¦ä¸²ï¼ˆå¦‚ '300px'ï¼‰"""
        if value is None:
            return default
        if isinstance(value, (int, float)):
            return int(value)
        if isinstance(value, str):
            # ç§»é™¤ 'px' åç¼€å¹¶è½¬æ¢ä¸ºæ•°å­—
            try:
                return int(value.replace('px', '').strip())
            except ValueError:
                return default
        return default

    def _get_subflow_node_ids(self) -> set[str]:
        """è·å–æ‰€æœ‰å­æµç¨‹åˆ†ç»„å†…çš„èŠ‚ç‚¹ID"""
        subflow_node_ids = set()
        
        # æ‰¾å‡ºæ‰€æœ‰å­æµç¨‹åˆ†ç»„å’Œå­æµç¨‹å¤´
        subflow_groups = []
        subflow_headers = []
        for node in self.workflow.nodes:
            if node.type == 'group' and node.data.get('isSubflow', False):
                subflow_groups.append(node)
            elif node.type == 'subflow_header':
                subflow_headers.append(node)
        
        # å¯¹äºæ¯ä¸ªå­æµç¨‹åˆ†ç»„ï¼Œæ‰¾å‡ºå…¶èŒƒå›´å†…çš„æ‰€æœ‰èŠ‚ç‚¹
        for group in subflow_groups:
            group_x = group.position.x
            group_y = group.position.y
            # ä¼˜å…ˆä» data å±æ€§è·å–å®½é«˜ï¼ˆå‰ç«¯ NodeResizer ä¿å­˜çš„ï¼‰ï¼Œå…¶æ¬¡ä» style å±æ€§è·å–
            group_width = group.data.get('width')
            group_height = group.data.get('height')
            if group_width is None or group_height is None:
                style = group.style or {}
                group_width = group_width or style.get('width', 300)
                group_height = group_height or style.get('height', 200)
            # ç¡®ä¿å®½é«˜æ˜¯æ•°å­—ç±»å‹
            group_width = self._parse_dimension(group_width, 300)
            group_height = self._parse_dimension(group_height, 200)
            
            for node in self.workflow.nodes:
                if node.id == group.id:
                    continue
                if node.type in ('group', 'note'):
                    continue
                # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åœ¨åˆ†ç»„èŒƒå›´å†…
                node_x = node.position.x
                node_y = node.position.y
                if (group_x <= node_x <= group_x + group_width and
                    group_y <= node_y <= group_y + group_height):
                    subflow_node_ids.add(node.id)
        
        # å¯¹äºå­æµç¨‹å¤´èŠ‚ç‚¹ï¼Œæ‰¾å‡ºä»å®ƒå¼€å§‹çš„æ‰€æœ‰è¿æ¥çš„èŠ‚ç‚¹
        for header in subflow_headers:
            # å­æµç¨‹å¤´èŠ‚ç‚¹æœ¬èº«ä¹Ÿè¦æ’é™¤
            subflow_node_ids.add(header.id)
            header_label = header.data.get('label', header.data.get('subflowName', 'æœªå‘½å'))
            print(f"[DEBUG] å¤„ç†å­æµç¨‹å¤´: {header.id}, åç§°: {header_label}")
            
            # ä»å­æµç¨‹å¤´å¼€å§‹ï¼Œæ²¿ç€è¿æ¥æ‰¾åˆ°æ‰€æœ‰èŠ‚ç‚¹ï¼ˆä½¿ç”¨BFSéå†æ•´ä¸ªå­æµç¨‹å›¾ï¼‰
            visited = set()
            queue = [header.id]
            
            while queue:
                current_id = queue.pop(0)
                if current_id in visited:
                    continue
                visited.add(current_id)
                
                # è·å–å½“å‰èŠ‚ç‚¹ä¿¡æ¯ç”¨äºè°ƒè¯•
                current_node = next((n for n in self.workflow.nodes if n.id == current_id), None)
                current_label = current_node.data.get('label', current_node.type) if current_node else 'unknown'
                
                # æ‰¾åˆ°ä»å½“å‰èŠ‚ç‚¹å‡ºå‘çš„æ‰€æœ‰è¾¹
                outgoing_edges = [e for e in self.workflow.edges if e.source == current_id]
                print(f"[DEBUG]   èŠ‚ç‚¹ {current_id} ({current_label}) æœ‰ {len(outgoing_edges)} æ¡å‡ºè¾¹")
                
                for edge in outgoing_edges:
                    if edge.target not in visited:
                        target_node = next((n for n in self.workflow.nodes if n.id == edge.target), None)
                        if target_node:
                            target_label = target_node.data.get('label', target_node.type)
                            print(f"[DEBUG]     -> è¾¹: {edge.source} -> {edge.target} (ç±»å‹: {target_node.type}, æ ‡ç­¾: {target_label})")
                            if target_node.type not in ('group', 'note', 'subflow_header'):
                                queue.append(edge.target)
                                subflow_node_ids.add(edge.target)
                                print(f"[DEBUG]       âœ“ æ·»åŠ åˆ°å­æµç¨‹èŠ‚ç‚¹åˆ—è¡¨")
                            else:
                                print(f"[DEBUG]       âœ— è·³è¿‡ (ç±»å‹: {target_node.type})")
            
            print(f"[DEBUG] å­æµç¨‹å¤´ {header.id} ({header_label}) æ”¶é›†åˆ° {len(visited)-1} ä¸ªèŠ‚ç‚¹")
        
        print(f"[DEBUG] ========================================")
        print(f"[DEBUG] æ€»å…±æ”¶é›†åˆ° {len(subflow_node_ids)} ä¸ªå­æµç¨‹èŠ‚ç‚¹")
        for node_id in subflow_node_ids:
            node = next((n for n in self.workflow.nodes if n.id == node_id), None)
            if node:
                label = node.data.get('label', node.type)
                print(f"[DEBUG]   - {node_id}: {node.type} ({label})")
        print(f"[DEBUG] ========================================")
        return subflow_node_ids

    async def _execute_subflow_group(self, group_id: str, subflow_name: str = None) -> ModuleResult:
        """æ‰§è¡Œå­æµç¨‹åˆ†ç»„å†…çš„æ¨¡å—"""
        # æ‰¾åˆ°å­æµç¨‹åˆ†ç»„æˆ–å­æµç¨‹å¤´ - ä¼˜å…ˆé€šè¿‡åç§°æŸ¥æ‰¾ï¼ˆå› ä¸ºå¯¼å…¥å ID ä¼šå˜ï¼‰ï¼ŒID ä½œä¸ºå¤‡ç”¨
        group_node = None
        is_header_mode = False
        
        # ä¼˜å…ˆé€šè¿‡åç§°æŸ¥æ‰¾
        if subflow_name:
            for node in self.workflow.nodes:
                # æŸ¥æ‰¾åˆ†ç»„å½¢å¼çš„å­æµç¨‹
                if (node.type == 'group' and 
                    node.data.get('isSubflow') == True and 
                    node.data.get('subflowName') == subflow_name):
                    group_node = node
                    break
                # æŸ¥æ‰¾å‡½æ•°å¤´å½¢å¼çš„å­æµç¨‹
                elif (node.type == 'subflow_header' and 
                      node.data.get('subflowName') == subflow_name):
                    group_node = node
                    is_header_mode = True
                    break
        
        # å¦‚æœé€šè¿‡åç§°æ‰¾ä¸åˆ°ï¼Œå°è¯•é€šè¿‡ ID æŸ¥æ‰¾
        if not group_node and group_id:
            for node in self.workflow.nodes:
                if node.id == group_id:
                    if node.type == 'group':
                        group_node = node
                        break
                    elif node.type == 'subflow_header':
                        group_node = node
                        is_header_mode = True
                        break
        
        if not group_node:
            error_msg = f"æ‰¾ä¸åˆ°å­æµç¨‹: {subflow_name or group_id}"
            return ModuleResult(success=False, error=error_msg)
        
        subflow_name = group_node.data.get('subflowName', 'å­æµç¨‹')
        await self._log(LogLevel.INFO, f"ğŸ“¦ å¼€å§‹æ‰§è¡Œå­æµç¨‹ [{subflow_name}]", is_system_log=True)
        
        # æ ¹æ®æ¨¡å¼è·å–å­æµç¨‹å†…çš„èŠ‚ç‚¹
        if is_header_mode:
            # å‡½æ•°å¤´æ¨¡å¼ï¼šä»å¤´èŠ‚ç‚¹å¼€å§‹ï¼Œæ²¿ç€è¿æ¥æ‰¾åˆ°æ‰€æœ‰èŠ‚ç‚¹
            nodes_in_group = []
            visited = set()
            queue = [group_node.id]
            
            while queue:
                current_id = queue.pop(0)
                if current_id in visited:
                    continue
                visited.add(current_id)
                
                # æ‰¾åˆ°ä»å½“å‰èŠ‚ç‚¹å‡ºå‘çš„æ‰€æœ‰è¾¹
                for edge in self.workflow.edges:
                    if edge.source == current_id and edge.target not in visited:
                        target_node = next((n for n in self.workflow.nodes if n.id == edge.target), None)
                        if target_node and target_node.type not in ('group', 'note', 'subflow_header'):
                            nodes_in_group.append(target_node)
                            queue.append(edge.target)
        else:
            # åˆ†ç»„æ¨¡å¼ï¼šè·å–åˆ†ç»„èŒƒå›´å†…çš„æ‰€æœ‰èŠ‚ç‚¹
            # è·å–åˆ†ç»„çš„ä½ç½®å’Œå¤§å°
            # ä¼˜å…ˆä» data å±æ€§è·å–å®½é«˜ï¼ˆå‰ç«¯ NodeResizer ä¿å­˜çš„ï¼‰ï¼Œå…¶æ¬¡ä» style å±æ€§è·å–
            group_x = group_node.position.x
            group_y = group_node.position.y
            group_width = group_node.data.get('width')
            group_height = group_node.data.get('height')
            if group_width is None or group_height is None:
                style = group_node.style or {}
                group_width = group_width or style.get('width', 300)
                group_height = group_height or style.get('height', 200)
            # ç¡®ä¿å®½é«˜æ˜¯æ•°å­—ç±»å‹
            group_width = self._parse_dimension(group_width, 300)
            group_height = self._parse_dimension(group_height, 200)
            
            # è°ƒè¯•ï¼šæ‰“å°åˆ†ç»„èŒƒå›´
            print(f"[DEBUG] å­æµç¨‹åˆ†ç»„èŒƒå›´: x={group_x}, y={group_y}, width={group_width}, height={group_height}")
            print(f"[DEBUG] åˆ†ç»„ data.width={group_node.data.get('width')}, data.height={group_node.data.get('height')}")
            
            # æ‰¾å‡ºåœ¨åˆ†ç»„èŒƒå›´å†…çš„æ‰€æœ‰èŠ‚ç‚¹
            nodes_in_group = []
            for node in self.workflow.nodes:
                if node.id == group_node.id:
                    continue
                if node.type in ('group', 'note'):
                    continue
                # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åœ¨åˆ†ç»„èŒƒå›´å†…
                node_x = node.position.x
                node_y = node.position.y
                # èŠ‚ç‚¹åœ¨åˆ†ç»„èŒƒå›´å†…çš„åˆ¤æ–­ï¼šèŠ‚ç‚¹å·¦ä¸Šè§’åœ¨åˆ†ç»„å†…
                if (group_x <= node_x <= group_x + group_width and
                    group_y <= node_y <= group_y + group_height):
                    nodes_in_group.append(node)
                    print(f"[DEBUG] èŠ‚ç‚¹åœ¨åˆ†ç»„å†…: {node.id} ({node.type}) at ({node_x}, {node_y})")
                else:
                    print(f"[DEBUG] èŠ‚ç‚¹ä¸åœ¨åˆ†ç»„å†…: {node.id} ({node.type}) at ({node_x}, {node_y})")
        
        if not nodes_in_group:
            await self._log(LogLevel.WARNING, f"ğŸ“¦ å­æµç¨‹ [{subflow_name}] ä¸ºç©º", is_system_log=True)
            return ModuleResult(success=True, message=f"å­æµç¨‹ [{subflow_name}] ä¸ºç©º")
        
        # æ‰¾å‡ºå­æµç¨‹å†…çš„èµ·å§‹èŠ‚ç‚¹ï¼ˆæ²¡æœ‰å…¥è¾¹çš„èŠ‚ç‚¹ï¼‰
        node_ids_in_group = {n.id for n in nodes_in_group}
        nodes_with_incoming = set()
        for edge in self.workflow.edges:
            if edge.target in node_ids_in_group and edge.source in node_ids_in_group:
                nodes_with_incoming.add(edge.target)
        
        start_nodes = [n for n in nodes_in_group if n.id not in nodes_with_incoming]
        
        if not start_nodes:
            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„èµ·å§‹èŠ‚ç‚¹ï¼ŒæŒ‰ä½ç½®æ’åºå–ç¬¬ä¸€ä¸ª
            start_nodes = sorted(nodes_in_group, key=lambda n: (n.position.y, n.position.x))[:1]
        
        # ä½¿ç”¨ä¸»æµç¨‹çš„æ‰§è¡Œé€»è¾‘æ¥æ‰§è¡Œå­æµç¨‹
        # ä¿å­˜å½“å‰æ‰§è¡ŒçŠ¶æ€
        original_executed_ids = self._executed_node_ids.copy()
        original_executing_ids = self._executing_node_ids.copy()
        original_pending_nodes = self._pending_nodes.copy()
        
        # é‡ç½®æ‰§è¡ŒçŠ¶æ€ï¼ˆä»…é’ˆå¯¹å­æµç¨‹å†…çš„èŠ‚ç‚¹ï¼‰
        # æ³¨æ„ï¼šä¸æ¸…ç©ºå…¨å±€çŠ¶æ€ï¼Œåªæ˜¯æ ‡è®°å­æµç¨‹å†…çš„èŠ‚ç‚¹ä¸ºæœªæ‰§è¡Œ
        subflow_executed_ids = set()
        
        try:
            # æ‰§è¡Œå­æµç¨‹çš„èµ·å§‹èŠ‚ç‚¹
            start_node_ids = [n.id for n in start_nodes]
            
            # ä½¿ç”¨ä¸»æµç¨‹çš„å¹¶è¡Œæ‰§è¡Œé€»è¾‘
            await self._execute_parallel_subflow(start_node_ids, node_ids_in_group, subflow_executed_ids)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯å‘ç”Ÿ
            subflow_error = None
            for node_id in subflow_executed_ids:
                # è¿™é‡Œæ— æ³•ç›´æ¥è·å–æ‰§è¡Œç»“æœï¼Œä½†å¦‚æœæœ‰é”™è¯¯ï¼Œä¸»æµç¨‹ä¼šå¤„ç†
                pass
            
            await self._log(LogLevel.INFO, f"ğŸ“¦ å­æµç¨‹ [{subflow_name}] æ‰§è¡Œå®Œæˆï¼Œå…±æ‰§è¡Œ {len(subflow_executed_ids)} ä¸ªèŠ‚ç‚¹", is_system_log=True)
            return ModuleResult(success=True, message=f"å­æµç¨‹ [{subflow_name}] æ‰§è¡Œå®Œæˆ")
            
        except Exception as e:
            await self._log(LogLevel.ERROR, f"ğŸ“¦ å­æµç¨‹ [{subflow_name}] æ‰§è¡Œå¤±è´¥: {str(e)}", is_system_log=True)
            return ModuleResult(success=False, error=f"å­æµç¨‹æ‰§è¡Œå¤±è´¥: {str(e)}")
        finally:
            # æ¢å¤åŸå§‹æ‰§è¡ŒçŠ¶æ€ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰
            # æ³¨æ„ï¼šå­æµç¨‹æ‰§è¡Œçš„èŠ‚ç‚¹åº”è¯¥è¢«æ ‡è®°ä¸ºå·²æ‰§è¡Œ
            pass
    
    async def _execute_parallel_subflow(self, node_ids: list[str], allowed_nodes: set[str], executed_ids: set[str]):
        """åœ¨å­æµç¨‹èŒƒå›´å†…å¹¶è¡Œæ‰§è¡ŒèŠ‚ç‚¹ï¼ˆæ”¯æŒå¾ªç¯ã€æ¡ä»¶ç­‰æ§åˆ¶æµï¼‰"""
        if not node_ids or self.should_stop:
            return
        
        # è¿‡æ»¤å‡ºå¯ä»¥æ‰§è¡Œçš„èŠ‚ç‚¹
        nodes_to_execute = []
        for node_id in node_ids:
            if node_id not in allowed_nodes:
                continue
            if node_id in executed_ids:
                continue
            
            # æ£€æŸ¥å‰ç½®èŠ‚ç‚¹æ˜¯å¦éƒ½å·²æ‰§è¡Œ
            prev_nodes = self.graph.get_prev_nodes(node_id)
            prev_in_subflow = [pid for pid in prev_nodes if pid in allowed_nodes]
            
            # å¦‚æœæ²¡æœ‰å‰ç½®èŠ‚ç‚¹ï¼Œæˆ–è€…æ‰€æœ‰å‰ç½®èŠ‚ç‚¹éƒ½å·²æ‰§è¡Œï¼Œåˆ™å¯ä»¥æ‰§è¡Œ
            if not prev_in_subflow or all(pid in executed_ids for pid in prev_in_subflow):
                nodes_to_execute.append(node_id)
        
        if not nodes_to_execute:
            return
        
        print(f"[DEBUG] _execute_parallel_subflow: å‡†å¤‡æ‰§è¡Œ {len(nodes_to_execute)} ä¸ªèŠ‚ç‚¹")
        for nid in nodes_to_execute:
            node = self.graph.get_node(nid)
            if node:
                label = node.data.get('label', node.type)
                print(f"[DEBUG]   - {nid}: {node.type} ({label})")
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å¯æ‰§è¡Œçš„èŠ‚ç‚¹
        tasks = [self._execute_node_in_subflow(node_id, allowed_nodes, executed_ids) for node_id in nodes_to_execute]
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _execute_node_in_subflow(self, node_id: str, allowed_nodes: set[str], executed_ids: set[str]):
        """åœ¨å­æµç¨‹ä¸­æ‰§è¡Œå•ä¸ªèŠ‚ç‚¹ï¼ˆæ”¯æŒå¾ªç¯ã€æ¡ä»¶ç­‰æ§åˆ¶æµï¼‰"""
        if node_id in executed_ids or self.should_stop:
            return
        
        node = self.graph.get_node(node_id)
        if not node:
            return
        
        # æ ‡è®°ä¸ºå·²æ‰§è¡Œ
        executed_ids.add(node_id)
        
        # å¤„ç†å¾ªç¯èŠ‚ç‚¹ï¼ˆç‰¹æ®Šå¤„ç†ï¼Œä¸ç›´æ¥æ‰§è¡Œï¼‰
        if node.type in ('loop', 'foreach'):
            body_nodes = self.graph.get_loop_body_nodes(node_id)
            done_nodes = self.graph.get_loop_done_nodes(node_id)
            
            print(f"[DEBUG] å­æµç¨‹ä¸­çš„å¾ªç¯èŠ‚ç‚¹ {node_id} ({node.type})")
            print(f"[DEBUG]   body_nodes: {body_nodes}")
            print(f"[DEBUG]   done_nodes: {done_nodes}")
            
            # åªå¤„ç†å­æµç¨‹èŒƒå›´å†…çš„å¾ªç¯ä½“å’Œå®Œæˆåˆ†æ”¯
            body_nodes_in_subflow = [nid for nid in body_nodes if nid in allowed_nodes]
            done_nodes_in_subflow = [nid for nid in done_nodes if nid in allowed_nodes]
            
            print(f"[DEBUG]   body_nodes_in_subflow: {body_nodes_in_subflow}")
            print(f"[DEBUG]   done_nodes_in_subflow: {done_nodes_in_subflow}")
            
            # è°ƒç”¨å¾ªç¯å¤„ç†é€»è¾‘
            await self._handle_loop_in_subflow(node, body_nodes_in_subflow, done_nodes_in_subflow, allowed_nodes, executed_ids)
            return
        
        # æ‰§è¡Œæ™®é€šèŠ‚ç‚¹
        result = await self._execute_node(node)
        
        # å¤„ç†æ‰§è¡Œç»“æœ
        if result and not result.success:
            # èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯åˆ†æ”¯
            error_nodes = self.graph.get_error_nodes(node_id)
            error_nodes_in_subflow = [nid for nid in error_nodes if nid in allowed_nodes]
            
            if error_nodes_in_subflow:
                # æœ‰é”™è¯¯åˆ†æ”¯ï¼Œç»§ç»­æ‰§è¡Œé”™è¯¯åˆ†æ”¯
                await self._execute_parallel_subflow(error_nodes_in_subflow, allowed_nodes, executed_ids)
                return
            else:
                # æ²¡æœ‰é”™è¯¯åˆ†æ”¯ï¼Œåœæ­¢æ‰§è¡Œ
                return
        
        # è·å–ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
        if result and result.branch:
            next_nodes = self.graph.get_next_nodes(node_id, result.branch)
        else:
            next_nodes = self.graph.get_next_nodes(node_id)
        
        # åªæ‰§è¡Œå­æµç¨‹èŒƒå›´å†…çš„èŠ‚ç‚¹
        next_nodes_in_subflow = [nid for nid in next_nodes if nid in allowed_nodes]
        
        # ç»§ç»­æ‰§è¡Œåç»­èŠ‚ç‚¹
        if next_nodes_in_subflow:
            await self._execute_parallel_subflow(next_nodes_in_subflow, allowed_nodes, executed_ids)
    
    async def _handle_loop_in_subflow(self, loop_node: WorkflowNode, body_nodes: list[str], done_nodes: list[str], allowed_nodes: set[str], executed_ids: set[str]):
        """åœ¨å­æµç¨‹ä¸­å¤„ç†å¾ªç¯æ‰§è¡Œ"""
        loop_config = loop_node.data
        
        # å…ˆæ‰§è¡Œå¾ªç¯èŠ‚ç‚¹æœ¬èº«ï¼Œè·å–å¾ªç¯çŠ¶æ€
        result = await self._execute_node(loop_node)
        if not result or not result.success:
            print(f"[DEBUG] å¾ªç¯èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥")
            return
        
        print(f"[DEBUG] å¾ªç¯èŠ‚ç‚¹æ‰§è¡ŒæˆåŠŸï¼Œresult.data: {result.data}")
        
        # ä»æ‰§è¡Œç»“æœä¸­è·å–å¾ªç¯çŠ¶æ€
        loop_state = result.data if result.data else {}
        loop_type = loop_state.get('type', loop_config.get('loopType', 'count'))
        
        print(f"[DEBUG] å¾ªç¯ç±»å‹: {loop_type}")
        print(f"[DEBUG] å¾ªç¯ä½“èŠ‚ç‚¹: {body_nodes}")
        
        # æ”¶é›†å¾ªç¯ä½“å†…çš„æ‰€æœ‰èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬åµŒå¥—çš„èŠ‚ç‚¹ï¼‰
        all_body_nodes = await self._collect_loop_body_nodes_in_subflow(body_nodes, allowed_nodes)
        print(f"[DEBUG] å¾ªç¯ä½“å†…æ‰€æœ‰èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬åµŒå¥—ï¼‰: {all_body_nodes}")
        
        if loop_type == 'count':
            # è®¡æ•°å¾ªç¯
            count = int(loop_config.get('count', 1))
            index_var = loop_config.get('indexVariable', 'loop_index')
            
            print(f"[DEBUG] å¼€å§‹è®¡æ•°å¾ªç¯ï¼Œæ¬¡æ•°: {count}")
            
            for i in range(count):
                if self.should_stop:
                    break
                
                self.context.variables[index_var] = i
                print(f"[DEBUG] å¾ªç¯ç¬¬ {i} æ¬¡ï¼Œæ‰§è¡Œå¾ªç¯ä½“")
                
                # æ‰§è¡Œå¾ªç¯ä½“ï¼ˆä»…å­æµç¨‹èŒƒå›´å†…ï¼‰
                if body_nodes:
                    # æ¯æ¬¡å¾ªç¯é‡ç½®å¾ªç¯ä½“å†…æ‰€æœ‰èŠ‚ç‚¹çš„æ‰§è¡ŒçŠ¶æ€
                    # æ³¨æ„ï¼šéœ€è¦å°†å¾ªç¯èŠ‚ç‚¹æœ¬èº«æ ‡è®°ä¸ºå·²æ‰§è¡Œï¼Œè¿™æ ·å¾ªç¯ä½“èŠ‚ç‚¹æ‰èƒ½æ‰§è¡Œ
                    body_executed = {loop_node.id}
                    await self._execute_parallel_subflow(body_nodes, allowed_nodes, body_executed)
                    print(f"[DEBUG] å¾ªç¯ç¬¬ {i} æ¬¡å®Œæˆï¼Œæ‰§è¡Œäº† {len(body_executed) - 1} ä¸ªèŠ‚ç‚¹: {body_executed - {loop_node.id}}")
                    # å°†å¾ªç¯ä½“æ‰§è¡Œçš„èŠ‚ç‚¹æ·»åŠ åˆ°æ€»æ‰§è¡Œåˆ—è¡¨ï¼ˆä¸åŒ…æ‹¬å¾ªç¯èŠ‚ç‚¹æœ¬èº«ï¼Œå› ä¸ºå®ƒå·²ç»åœ¨å¤–å±‚æ‰§è¡Œè¿‡äº†ï¼‰
                    executed_ids.update(body_executed - {loop_node.id})
        
        elif loop_type == 'while':
            # æ¡ä»¶å¾ªç¯
            condition = loop_config.get('condition', '')
            index_var = loop_config.get('indexVariable', 'loop_index')
            max_iterations = 1000
            iteration = 0
            
            print(f"[DEBUG] å¼€å§‹æ¡ä»¶å¾ªç¯ï¼Œæ¡ä»¶: {condition}")
            
            while iteration < max_iterations:
                if self.should_stop:
                    break
                
                try:
                    should_continue = eval(condition, {"__builtins__": {}}, self.context.variables)
                    if not should_continue:
                        print(f"[DEBUG] æ¡ä»¶ä¸æ»¡è¶³ï¼Œé€€å‡ºå¾ªç¯")
                        break
                except Exception as e:
                    await self._log(LogLevel.ERROR, f"å¾ªç¯æ¡ä»¶æ±‚å€¼å¤±è´¥: {str(e)}", node_id=loop_node.id)
                    break
                
                self.context.variables[index_var] = iteration
                print(f"[DEBUG] å¾ªç¯ç¬¬ {iteration} æ¬¡ï¼Œæ‰§è¡Œå¾ªç¯ä½“")
                
                # æ‰§è¡Œå¾ªç¯ä½“ï¼ˆä»…å­æµç¨‹èŒƒå›´å†…ï¼‰
                if body_nodes:
                    body_executed = {loop_node.id}
                    await self._execute_parallel_subflow(body_nodes, allowed_nodes, body_executed)
                    print(f"[DEBUG] å¾ªç¯ç¬¬ {iteration} æ¬¡å®Œæˆï¼Œæ‰§è¡Œäº† {len(body_executed) - 1} ä¸ªèŠ‚ç‚¹: {body_executed - {loop_node.id}}")
                    executed_ids.update(body_executed - {loop_node.id})
                
                iteration += 1
        
        elif loop_type == 'foreach':
            # éå†åˆ—è¡¨
            data = loop_state.get('data', [])
            item_var = loop_state.get('item_variable', 'item')
            index_var = loop_state.get('index_variable', 'index')
            
            print(f"[DEBUG] å¼€å§‹éå†å¾ªç¯ï¼Œæ•°æ®é•¿åº¦: {len(data)}")
            
            for i, item in enumerate(data):
                if self.should_stop:
                    break
                
                # è®¾ç½®å¾ªç¯å˜é‡
                self.context.variables[item_var] = item
                self.context.variables[index_var] = i
                print(f"[DEBUG] å¾ªç¯ç¬¬ {i} æ¬¡ï¼Œitem={item}")
                
                # æ‰§è¡Œå¾ªç¯ä½“ï¼ˆä»…å­æµç¨‹èŒƒå›´å†…ï¼‰
                if body_nodes:
                    body_executed = {loop_node.id}
                    await self._execute_parallel_subflow(body_nodes, allowed_nodes, body_executed)
                    print(f"[DEBUG] å¾ªç¯ç¬¬ {i} æ¬¡å®Œæˆï¼Œæ‰§è¡Œäº† {len(body_executed) - 1} ä¸ªèŠ‚ç‚¹: {body_executed - {loop_node.id}}")
                    executed_ids.update(body_executed - {loop_node.id})
        
        # æ¸…ç†å¾ªç¯çŠ¶æ€
        if self.context.loop_stack and self.context.loop_stack[-1].get('type') == loop_type:
            self.context.loop_stack.pop()
        
        print(f"[DEBUG] å¾ªç¯ç»“æŸï¼Œæ‰§è¡Œå®Œæˆåˆ†æ”¯: {done_nodes}")
        
        # å¾ªç¯ç»“æŸåæ‰§è¡Œå®Œæˆåˆ†æ”¯ï¼ˆä»…å­æµç¨‹èŒƒå›´å†…ï¼‰
        if done_nodes:
            await self._execute_parallel_subflow(done_nodes, allowed_nodes, executed_ids)
    
    async def _collect_loop_body_nodes_in_subflow(self, start_nodes: list[str], allowed_nodes: set[str]) -> set[str]:
        """æ”¶é›†å­æµç¨‹ä¸­å¾ªç¯ä½“å†…çš„æ‰€æœ‰èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬åµŒå¥—çš„èŠ‚ç‚¹ï¼‰"""
        collected = set()
        to_visit = list(start_nodes)
        
        while to_visit:
            node_id = to_visit.pop(0)
            if node_id in collected or node_id not in allowed_nodes:
                continue
            collected.add(node_id)
            
            node = self.graph.get_node(node_id)
            if not node:
                continue
            
            # è·å–æ‰€æœ‰åç»§èŠ‚ç‚¹
            next_nodes = []
            
            # å¦‚æœæ˜¯æ¡ä»¶èŠ‚ç‚¹ï¼Œè·å–æ‰€æœ‰åˆ†æ”¯
            if node.type == 'condition':
                if node_id in self.graph.condition_branches:
                    for branch_target in self.graph.condition_branches[node_id].values():
                        if branch_target:
                            next_nodes.append(branch_target)
            # å¦‚æœæ˜¯å¾ªç¯èŠ‚ç‚¹ï¼Œè·å–å¾ªç¯ä½“å’Œå®Œæˆåˆ†æ”¯
            elif node.type in ('loop', 'foreach'):
                if node_id in self.graph.loop_branches:
                    for branch_targets in self.graph.loop_branches[node_id].values():
                        next_nodes.extend(branch_targets)
            else:
                # æ™®é€šèŠ‚ç‚¹ï¼Œè·å–é»˜è®¤åç»§
                next_nodes = self.graph.get_next_nodes(node_id)
            
            for next_id in next_nodes:
                if next_id not in collected and next_id in allowed_nodes:
                    to_visit.append(next_id)
        
        return collected


    async def _handle_loop(self, loop_node: WorkflowNode, body_nodes: list[str], done_nodes: list[str]):
        """å¤„ç†å¾ªç¯æ‰§è¡Œ"""
        if not self.context.loop_stack:
            await self._notify_successors(done_nodes, loop_node.id)
            return
        
        loop_state = self.context.loop_stack[-1]
        loop_type = loop_state['type']
        
        while not self.should_stop:
            should_continue = False
            
            if loop_type == 'count':
                should_continue = loop_state['current_index'] < loop_state['count']
            elif loop_type == 'range':
                current = loop_state['current_index']
                end_value = loop_state['end_value']
                step_value = loop_state['step_value']
                should_continue = current <= end_value if step_value > 0 else current >= end_value
            elif loop_type == 'while':
                condition_value = self.context.get_variable(loop_state['condition'], False)
                should_continue = bool(condition_value)
            elif loop_type == 'foreach':
                should_continue = loop_state['current_index'] < len(loop_state['data'])
            
            if not should_continue:
                break
            
            self.context.should_continue = False
            
            if body_nodes:
                async with self._node_lock:
                    for nid in body_nodes:
                        self._executed_node_ids.discard(nid)
                        self._executing_node_ids.discard(nid)
                
                # æ”¶é›†å¾ªç¯ä½“å†…çš„æ‰€æœ‰èŠ‚ç‚¹
                all_body_nodes = await self._collect_loop_body_nodes(body_nodes)
                
                # æ”¶é›†é”™è¯¯å¤„ç†åˆ†æ”¯çš„èŠ‚ç‚¹
                error_branch_nodes = self._collect_error_branch_nodes(all_body_nodes)
                
                async with self._node_lock:
                    # æ¸…é™¤å¾ªç¯ä½“èŠ‚ç‚¹çš„æ‰§è¡ŒçŠ¶æ€
                    for nid in all_body_nodes:
                        self._executed_node_ids.discard(nid)
                        self._executing_node_ids.discard(nid)
                        # æ¸…é™¤å¾…å¤„ç†èŠ‚ç‚¹çš„å‰é©±ç­‰å¾…çŠ¶æ€
                        if nid in self._pending_nodes:
                            del self._pending_nodes[nid]
                    
                    # æ¸…é™¤é”™è¯¯å¤„ç†åˆ†æ”¯èŠ‚ç‚¹çš„æ‰§è¡ŒçŠ¶æ€ï¼ˆè¿™æ ·ä¸‹æ¬¡å¾ªç¯å¦‚æœå†æŠ¥é”™ï¼Œé”™è¯¯å¤„ç†æµç¨‹å¯ä»¥å†æ¬¡æ‰§è¡Œï¼‰
                    for nid in error_branch_nodes:
                        self._executed_node_ids.discard(nid)
                        self._executing_node_ids.discard(nid)
                        if nid in self._pending_nodes:
                            del self._pending_nodes[nid]
                
                await self._execute_parallel(body_nodes)
            
            if self.context.should_break:
                self.context.should_break = False
                break
            
            if loop_type == 'count':
                loop_state['current_index'] += 1
                self.context.set_variable(loop_state['index_variable'], loop_state['current_index'])
            elif loop_type == 'range':
                loop_state['current_index'] += loop_state['step_value']
                self.context.set_variable(loop_state['index_variable'], loop_state['current_index'])
            elif loop_type == 'foreach':
                loop_state['current_index'] += 1
                if loop_state['current_index'] < len(loop_state['data']):
                    self.context.set_variable(loop_state['item_variable'], 
                                              loop_state['data'][loop_state['current_index']])
                    self.context.set_variable(loop_state['index_variable'], loop_state['current_index'])
        
        if self.context.loop_stack:
            self.context.loop_stack.pop()
        
        if done_nodes and not self.should_stop:
            await self._execute_parallel(done_nodes)

    async def _collect_loop_body_nodes(self, start_nodes: list[str]) -> set[str]:
        """æ”¶é›†å¾ªç¯ä½“å†…çš„æ‰€æœ‰èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬æ¡ä»¶åˆ†æ”¯çš„æ‰€æœ‰è·¯å¾„ï¼‰
        
        æ³¨æ„ï¼šä¸æ”¶é›†é”™è¯¯å¤„ç†åˆ†æ”¯çš„èŠ‚ç‚¹ï¼Œå› ä¸ºé”™è¯¯å¤„ç†åˆ†æ”¯åªåœ¨èŠ‚ç‚¹å¤±è´¥æ—¶æ‰æ‰§è¡Œã€‚
        é”™è¯¯å¤„ç†åˆ†æ”¯çš„èŠ‚ç‚¹ä¼šåœ¨ _collect_error_branch_nodes ä¸­å•ç‹¬æ”¶é›†ã€‚
        """
        collected = set()
        to_visit = list(start_nodes)
        
        while to_visit:
            node_id = to_visit.pop(0)
            if node_id in collected:
                continue
            collected.add(node_id)
            
            node = self.graph.get_node(node_id)
            if not node:
                continue
            
            # è·å–æ‰€æœ‰åç»§èŠ‚ç‚¹
            next_nodes = []
            
            # å¦‚æœæ˜¯æ¡ä»¶èŠ‚ç‚¹ï¼Œè·å–æ‰€æœ‰åˆ†æ”¯
            if node.type == 'condition':
                if node_id in self.graph.condition_branches:
                    for branch_target in self.graph.condition_branches[node_id].values():
                        if branch_target:
                            next_nodes.append(branch_target)
            # å¦‚æœæ˜¯å¾ªç¯èŠ‚ç‚¹ï¼Œè·å–å¾ªç¯ä½“å’Œå®Œæˆåˆ†æ”¯
            elif node.type in ('loop', 'foreach'):
                if node_id in self.graph.loop_branches:
                    for branch_targets in self.graph.loop_branches[node_id].values():
                        next_nodes.extend(branch_targets)
            else:
                # æ™®é€šèŠ‚ç‚¹ï¼Œè·å–é»˜è®¤åç»§
                next_nodes = self.graph.get_next_nodes(node_id)
            
            for next_id in next_nodes:
                if next_id not in collected:
                    to_visit.append(next_id)
        
        return collected

    def _collect_error_branch_nodes(self, body_nodes: set[str]) -> set[str]:
        """æ”¶é›†å¾ªç¯ä½“å†…æ‰€æœ‰èŠ‚ç‚¹çš„é”™è¯¯å¤„ç†åˆ†æ”¯èŠ‚ç‚¹"""
        error_nodes = set()
        to_visit = []
        
        # é¦–å…ˆæ”¶é›†å¾ªç¯ä½“å†…æ‰€æœ‰èŠ‚ç‚¹çš„ç›´æ¥é”™è¯¯å¤„ç†åˆ†æ”¯
        for node_id in body_nodes:
            error_branch_nodes = self.graph.get_error_nodes(node_id)
            for error_node_id in error_branch_nodes:
                if error_node_id not in body_nodes and error_node_id not in error_nodes:
                    to_visit.append(error_node_id)
        
        # ç„¶åé€’å½’æ”¶é›†é”™è¯¯å¤„ç†åˆ†æ”¯çš„åç»§èŠ‚ç‚¹
        while to_visit:
            node_id = to_visit.pop(0)
            if node_id in error_nodes or node_id in body_nodes:
                continue
            error_nodes.add(node_id)
            
            node = self.graph.get_node(node_id)
            if not node:
                continue
            
            # è·å–åç»§èŠ‚ç‚¹
            next_nodes = self.graph.get_next_nodes(node_id)
            for next_id in next_nodes:
                if next_id not in error_nodes and next_id not in body_nodes:
                    to_visit.append(next_id)
            
            # é”™è¯¯å¤„ç†åˆ†æ”¯çš„èŠ‚ç‚¹ä¹Ÿå¯èƒ½æœ‰è‡ªå·±çš„é”™è¯¯å¤„ç†åˆ†æ”¯
            error_branch_nodes = self.graph.get_error_nodes(node_id)
            for error_node_id in error_branch_nodes:
                if error_node_id not in error_nodes and error_node_id not in body_nodes:
                    to_visit.append(error_node_id)
        
        return error_nodes
        
        return collected

    async def _cleanup(self):
        """æ¸…ç†èµ„æºï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œæ¸…ç†æ‰€æœ‰èµ„æºåŒ…æ‹¬æµè§ˆå™¨ï¼‰"""
        try:
            # ç»ˆæ­¢æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„ FFmpeg è¿›ç¨‹
            try:
                from app.executors.media import ffmpeg_manager
                await ffmpeg_manager.terminate_all()
            except Exception as e:
                print(f"æ¸…ç† FFmpeg è¿›ç¨‹æ—¶å‡ºé”™: {e}")
            
            if self.context.page:
                try:
                    await self.context.page.close()
                except:
                    pass
                self.context.page = None
            
            if self.context.browser_context:
                try:
                    await self.context.browser_context.close()
                except:
                    pass
                self.context.browser_context = None
            
            if self.context.browser:
                try:
                    await self.context.browser.close()
                except:
                    pass
                self.context.browser = None
            
            if self.context._playwright:
                try:
                    await self.context._playwright.stop()
                except:
                    pass
                self.context._playwright = None
            
            # æ¸…ç†ä¸Šä¸‹æ–‡ä¸­çš„æ•°æ®ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
            self.context.variables.clear()
            self.context.data_rows.clear()
            self.context.current_row.clear()
            self.context.loop_stack.clear()
            
            # æ¸…ç†æ‰§è¡Œå™¨å†…éƒ¨çŠ¶æ€
            self._executed_node_ids.clear()
            self._executing_node_ids.clear()
            self._pending_nodes.clear()
            self._running_tasks.clear()
            self.graph = None
            
        except Exception as e:
            print(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")
    
    async def cleanup(self):
        """æ¸…ç†æµè§ˆå™¨èµ„æºï¼ˆå…¬å…±æ–¹æ³•ï¼Œä»…æ¸…ç†æµè§ˆå™¨ï¼‰"""
        try:
            if self.context.page:
                try:
                    await self.context.page.close()
                except:
                    pass
                self.context.page = None
            
            if self.context.browser_context:
                try:
                    await self.context.browser_context.close()
                except:
                    pass
                self.context.browser_context = None
            
            if self.context.browser:
                try:
                    await self.context.browser.close()
                except:
                    pass
                self.context.browser = None
            
            if self.context._playwright:
                try:
                    await self.context._playwright.stop()
                except:
                    pass
                self.context._playwright = None
        except Exception as e:
            print(f"å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™: {e}")


    async def execute(self) -> ExecutionResult:
        """æ‰§è¡Œå·¥ä½œæµ"""
        from playwright.async_api import async_playwright
        import os
        
        self.is_running = True
        self.should_stop = False
        self.start_time = datetime.now()
        self.executed_nodes = 0
        self.failed_nodes = 0
        self._executed_node_ids.clear()
        self._executing_node_ids.clear()
        self._pending_nodes.clear()
        self._last_data_rows_count = 0
        self._sent_data_rows_count = 0
        self._running_tasks.clear()
        
        self.context.variables.clear()
        self.context.data_rows.clear()
        self.context.current_row.clear()
        self.context.loop_stack.clear()
        self.context.should_break = False
        self.context.should_continue = False
        
        for var in self.workflow.variables:
            self.context.set_variable(var.name, var.value)
        
        await self._log(LogLevel.INFO, "ğŸš€ å·¥ä½œæµå¼€å§‹æ‰§è¡Œ", is_system_log=True)
        
        try:
            parser = WorkflowParser(self.workflow)
            self.graph = parser.parse()
            
            playwright = await async_playwright().start()
            self.context._playwright = playwright
            
            # è·å–æµè§ˆå™¨æ•°æ®ç›®å½•ï¼šä¼˜å…ˆä½¿ç”¨å…¨å±€é…ç½®ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤ç›®å½•
            if self.browser_config and self.browser_config.get('userDataDir'):
                user_data_dir_base = self.browser_config.get('userDataDir')
            else:
                # ä½¿ç”¨é»˜è®¤ç›®å½•ï¼ˆè·å–ç»å¯¹è·¯å¾„ï¼‰
                backend_dir = os.path.abspath(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
                user_data_dir_base = os.path.join(backend_dir, 'browser_data')
            
            # è·å–æµè§ˆå™¨ç±»å‹ï¼Œä¸ºä¸åŒæµè§ˆå™¨ä½¿ç”¨ä¸åŒçš„å­ç›®å½•
            browser_type = self.browser_config.get('type', 'msedge') if self.browser_config else 'msedge'
            user_data_dir = os.path.join(user_data_dir_base, browser_type)
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(user_data_dir, exist_ok=True)
            self.context._user_data_dir = user_data_dir
            print(f"[WorkflowExecutor] ä½¿ç”¨æµè§ˆå™¨æ•°æ®ç›®å½•: {user_data_dir}")
            
            # æ”¶é›†æ‰€æœ‰å­æµç¨‹åˆ†ç»„å†…çš„èŠ‚ç‚¹IDï¼ˆè¿™äº›èŠ‚ç‚¹ä¸åº”è¯¥è¢«ä¸»æµç¨‹ç›´æ¥æ‰§è¡Œï¼‰
            self._subflow_node_ids = self._get_subflow_node_ids()
            
            start_nodes = self.graph.get_start_nodes()
            # è¿‡æ»¤æ‰å­æµç¨‹å†…çš„èµ·å§‹èŠ‚ç‚¹
            start_nodes = [nid for nid in start_nodes if nid not in self._subflow_node_ids]
            
            # è°ƒè¯•ï¼šæ‰“å°èµ·å§‹èŠ‚ç‚¹ä¿¡æ¯
            print(f"[DEBUG] æ‰¾åˆ° {len(start_nodes)} ä¸ªèµ·å§‹èŠ‚ç‚¹:")
            for nid in start_nodes:
                node = self.graph.get_node(nid)
                if node:
                    label = node.data.get('label', node.type)
                    print(f"  - {nid}: {node.type} ({label})")
            
            # è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰èŠ‚ç‚¹å’Œè¾¹çš„ä¿¡æ¯
            print(f"[DEBUG] å·¥ä½œæµå…±æœ‰ {len(self.graph.nodes)} ä¸ªèŠ‚ç‚¹:")
            for nid, node in self.graph.nodes.items():
                label = node.data.get('label', node.type)
                prev_nodes = self.graph.get_prev_nodes(nid)
                next_nodes = self.graph.get_next_nodes(nid)
                print(f"  - {nid}: {node.type} ({label})")
                print(f"    å‰é©±: {prev_nodes}")
                print(f"    åç»§: {next_nodes}")
            
            if not start_nodes:
                await self._log(LogLevel.WARNING, "æ²¡æœ‰æ‰¾åˆ°èµ·å§‹èŠ‚ç‚¹")
            else:
                await self._execute_parallel(start_nodes)
            
            if self.context.current_row:
                self.context.commit_row()
                if len(self.context.data_rows) > self._last_data_rows_count:
                    for i in range(self._last_data_rows_count, len(self.context.data_rows)):
                        await self._send_data_row(self.context.data_rows[i])
            
            if self.should_stop:
                status = ExecutionStatus.STOPPED
                await self._log(LogLevel.WARNING, "â¹ï¸ å·¥ä½œæµå·²åœæ­¢", is_system_log=True)
            elif self.failed_nodes > 0:
                status = ExecutionStatus.FAILED
                await self._log(LogLevel.ERROR, f"âŒ å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼Œæœ‰ {self.failed_nodes} ä¸ªèŠ‚ç‚¹å¤±è´¥", is_system_log=True)
            else:
                status = ExecutionStatus.COMPLETED
                duration = (datetime.now() - self.start_time).total_seconds()
                await self._log(LogLevel.SUCCESS, f"âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼Œå…±æ‰§è¡Œ {self.executed_nodes} ä¸ªèŠ‚ç‚¹ï¼Œè€—æ—¶ {duration:.2f}ç§’", is_system_log=True)
            
            self._result = ExecutionResult(
                workflow_id=self.workflow.id,
                status=status,
                started_at=self.start_time,
                completed_at=datetime.now(),
                total_nodes=len(self.workflow.nodes),
                executed_nodes=self.executed_nodes,
                failed_nodes=self.failed_nodes,
            )
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            await self._log(LogLevel.ERROR, f"ğŸ’¥ å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸: {str(e)}", is_system_log=True)
            self._result = ExecutionResult(
                workflow_id=self.workflow.id,
                status=ExecutionStatus.FAILED,
                started_at=self.start_time,
                completed_at=datetime.now(),
                total_nodes=len(self.workflow.nodes),
                executed_nodes=self.executed_nodes,
                failed_nodes=self.failed_nodes,
                error_message=str(e),
            )
        finally:
            # æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œè‡ªåŠ¨æ¸…ç†æµè§ˆå™¨ï¼Œç”±è°ƒç”¨æ–¹æ ¹æ® autoCloseBrowser é…ç½®å†³å®šæ˜¯å¦å…³é—­
            # ä½†éœ€è¦æ¸…ç†å…¶ä»–èµ„æº
            try:
                # æ¢å¤æ‰‹æœºè¾“å…¥æ³•ï¼ˆå¦‚æœä¹‹å‰åˆ‡æ¢è¿‡ï¼‰
                try:
                    original_ime = self.context.variables.get('original_ime')
                    if original_ime:
                        print(f"[WorkflowExecutor] æ¢å¤åŸè¾“å…¥æ³•: {original_ime}")
                        from app.services.adb_manager import get_adb_manager
                        adb = get_adb_manager()
                        success, error = adb.restore_ime(original_ime)
                        if success:
                            print(f"[WorkflowExecutor] è¾“å…¥æ³•å·²æ¢å¤")
                        else:
                            print(f"[WorkflowExecutor] æ¢å¤è¾“å…¥æ³•å¤±è´¥: {error}")
                        # æ¸…é™¤å˜é‡
                        del self.context.variables['original_ime']
                except Exception as e:
                    print(f"æ¢å¤è¾“å…¥æ³•æ—¶å‡ºé”™: {e}")
                
                # ç»ˆæ­¢æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„ FFmpeg è¿›ç¨‹
                try:
                    from app.executors.media import ffmpeg_manager
                    await ffmpeg_manager.terminate_all()
                except Exception as e:
                    print(f"æ¸…ç† FFmpeg è¿›ç¨‹æ—¶å‡ºé”™: {e}")
                
                # æ¸…ç†ä¸Šä¸‹æ–‡ä¸­çš„æ•°æ®ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
                # âš ï¸ æ³¨æ„ï¼šä¸è¦æ¸…ç©º variablesï¼Œå› ä¸ºå¤–éƒ¨éœ€è¦ä¿å­˜å…¨å±€å˜é‡
                # self.context.variables.clear()  # âŒ ä¸è¦æ¸…ç©ºï¼
                self.context.data_rows.clear()
                self.context.current_row.clear()
                self.context.loop_stack.clear()
                
                # æ¸…ç†æ‰§è¡Œå™¨å†…éƒ¨çŠ¶æ€
                self._executed_node_ids.clear()
                self._executing_node_ids.clear()
                self._pending_nodes.clear()
                self._running_tasks.clear()
                self.graph = None
            except Exception as e:
                print(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")
            
            self.is_running = False
        
        return self._result

    async def stop(self):
        """åœæ­¢å·¥ä½œæµæ‰§è¡Œ - ç«‹å³å¼ºåˆ¶åœæ­¢æ‰€æœ‰æ“ä½œ"""
        self.should_stop = True
        await self._log(LogLevel.WARNING, "æ­£åœ¨åœæ­¢å·¥ä½œæµ...", is_system_log=True)
        
        # 1. ç»ˆæ­¢æ‰€æœ‰æ­£åœ¨è¿è¡Œçš„ FFmpeg è¿›ç¨‹
        try:
            from app.executors.media import ffmpeg_manager
            await ffmpeg_manager.terminate_all()
        except Exception as e:
            print(f"ç»ˆæ­¢ FFmpeg è¿›ç¨‹æ—¶å‡ºé”™: {e}")
        
        # 2. å–æ¶ˆæ‰€æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
        for task in list(self._running_tasks):
            if not task.done():
                task.cancel()
        
        # ç­‰å¾…ä»»åŠ¡å–æ¶ˆå®Œæˆï¼ˆæœ€å¤š1ç§’ï¼‰
        if self._running_tasks:
            try:
                await asyncio.wait(list(self._running_tasks), timeout=1.0)
            except:
                pass
        self._running_tasks.clear()
        
        # 3. å¼ºåˆ¶å…³é—­æµè§ˆå™¨ä»¥ä¸­æ–­æ­£åœ¨è¿›è¡Œçš„æ“ä½œ
        try:
            if self.context.page:
                try:
                    await self.context.page.close()
                except:
                    pass
                self.context.page = None
            
            if self.context.browser_context:
                try:
                    await self.context.browser_context.close()
                except:
                    pass
                self.context.browser_context = None
            
            if self.context.browser:
                try:
                    await self.context.browser.close()
                except:
                    pass
                self.context.browser = None
            
            if self.context._playwright:
                try:
                    await self.context._playwright.stop()
                except:
                    pass
                self.context._playwright = None
        except Exception as e:
            print(f"åœæ­¢æ—¶å…³é—­æµè§ˆå™¨å‡ºé”™: {e}")
        
        self.is_running = False

    def get_collected_data(self) -> list[dict]:
        """è·å–æ”¶é›†çš„æ•°æ®"""
        if self.context.current_row:
            self.context.commit_row()
        return self.context.data_rows.copy()
